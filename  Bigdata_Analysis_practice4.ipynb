{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":" Bigdata_Analysis_practice4.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP/Q9VqAoSrRAwHZ4FaISsr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 전처리"],"metadata":{"id":"z6_aarnWKHwQ"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ILOt_2LtJ_ya","executionInfo":{"status":"ok","timestamp":1656040094535,"user_tz":-540,"elapsed":16714,"user":{"displayName":"Jeongeum Lee","userId":"01112082482943907602"}},"outputId":"3067e272-bc86-4a19-d73d-d6f63dd96dbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"/content/drive/MyDrive/Colab Notebooks\")"]},{"cell_type":"markdown","source":["# 2022-06-21"],"metadata":{"id":"MDLqSFdx1E9h"}},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 1. 로지스틱 회귀모델\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import pandas as pd\n","data = pd.read_csv(\"breast-cancer-wisconsin.csv\")\n","\n","x = data[data.columns[:10]]\n","y = data[[\"Class\"]]\n","\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42, stratify = y)\n","\n","from sklearn.preprocessing import MinMaxScaler\n","scaler_minmax = MinMaxScaler()\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.linear_model import LogisticRegression\n","model = LogisticRegression()\n","model.fit(x_scaled_train, y_train)\n","pred_train = model.predict(x_scaled_train)\n","pred_test = model.predict(x_scaled_test)\n","\n","from sklearn.metrics import confusion_matrix\n","confusion_train = confusion_matrix(y_train, pred_train)\n","print(confusion_train)\n","\n","from sklearn.metrics import classification_report\n","report = classification_report(y_train, pred_train)\n","print(report)\n","\n","from sklearn.model_selection import GridSearchCV\n","param_grid = {\"C\": [0.001, 0.01, 0.1, 1, 10, 100]}\n","grid_search = GridSearchCV(LogisticRegression(), param_grid, cv = 5, return_train_score = True)\n","grid_search.fit(x_scaled_train, y_train)\n","print(f\"가장 높은 점수, 파라미터 : {grid_search.best_score_}, {grid_search.best_params_}\")\n","\n","from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import randint\n","param_distrib = {\"C\": randint(low = 0.001, high = 100)}\n","random_search = RandomizedSearchCV(LogisticRegression(), param_distrib, n_iter = 100, cv = 5, return_train_score = True)\n","random_search.fit(x_scaled_train, y_train)\n","print(f\"가장 높은 점수, 파라미터 : {random_search.best_score_}, {random_search.best_params_}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BrP_ULvuKJKp","executionInfo":{"status":"ok","timestamp":1655804367693,"user_tz":-540,"elapsed":9754,"user":{"displayName":"Jeongeum Lee","userId":"01112082482943907602"}},"outputId":"74f4ba80-8baa-4cc0-936c-105b5c8c6cd6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[328   5]\n"," [  9 170]]\n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.98      0.98       333\n","           1       0.97      0.95      0.96       179\n","\n","    accuracy                           0.97       512\n","   macro avg       0.97      0.97      0.97       512\n","weighted avg       0.97      0.97      0.97       512\n","\n","가장 높은 점수, 파라미터 : 0.972606129830573, {'C': 10}\n","가장 높은 점수, 파라미터 : 0.9745478774033887, {'C': 13}\n"]}]},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 2. K - Nearest Neighbor(KNN)\n","# 회귀문제와 분류문제 둘다에 쓸 수 있다.\n","# sklearn.neighbors 안의 KNeighborsClassifier 와 KNeighborsRegressor가 바로 그것이다.\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import pandas as pd\n","data = pd.read_csv(\"breast-cancer-wisconsin.csv\")\n","\n","# 분류문제\n","x = data[data.columns[:10]]\n","y = data[[\"Class\"]]\n","\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42, stratify = y)\n","\n","from sklearn.preprocessing import MinMaxScaler\n","scaler_minmax = MinMaxScaler()\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n","model = KNeighborsClassifier()\n","model.fit(x_scaled_train, y_train)\n","pred_train = model.predict(x_scaled_train)\n","model.score(x_scaled_test, y_test)\n","\n","from sklearn.model_selection import GridSearchCV\n","param_grid = {\"n_neighbors\": [1, 3, 5, 7, 9, 11]}\n","grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv = 5)\n","grid_search.fit(x_scaled_train, y_train)\n","print(f\"가장 높은 점수, 파라미터 : {grid_search.best_score_}, {grid_search.best_params_}\")\n","print(f\"테스트 데이터 점수 : {grid_search.score(x_scaled_test, y_test)}\")\n","\n","from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import randint\n","param_distrib = {\"n_neighbors\": randint(low = 1, high = 20)}\n","random_search = RandomizedSearchCV(KNeighborsClassifier(), param_distrib, cv = 5, n_iter = 20)\n","random_search.fit(x_scaled_train, y_train)\n","print(f\"가장 높은 점수, 파라미터 : {random_search.best_score_}, {random_search.best_params_}\")\n","print(f\"테스트 데이터 점수 : {random_search.score(x_scaled_test, y_test)}\")\n","\n","\n","# 회귀문제\n","data2 = pd.read_csv(\"house_price.csv\")\n","x = data2[data2.columns[:5]]\n","y = data2[[\"house_value\"]]\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42)\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","param_grid = {\"n_neighbors\": [25, 30, 35, 40, 45, 50, 55, 60]}\n","grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv = 5)\n","grid_search.fit(x_scaled_train, y_train)\n","print(f\"가장 높은 점수, 파라미터 : {grid_search.best_score_}, {grid_search.best_params_}\")\n","print(f\"테스트 데이터 점수 : {grid_search.score(x_scaled_test, y_test)}\")\n","\n","param_distrib = {\"n_neighbors\": randint(low = 1, high = 20)}\n","random_search = RandomizedSearchCV(KNeighborsRegressor(), param_distrib, cv = 5, n_iter = 20)\n","random_search.fit(x_scaled_train, y_train)\n","print(f\"가장 높은 점수, 파라미터 : {random_search.best_score_}, {random_search.best_params_}\")\n","print(f\"테스트 데이터 점수 : {random_search.score(x_scaled_test, y_test)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Iu1I-jh9VlK","executionInfo":{"status":"ok","timestamp":1655804389688,"user_tz":-540,"elapsed":22007,"user":{"displayName":"Jeongeum Lee","userId":"01112082482943907602"}},"outputId":"2eb94418-769f-4f76-9aea-68b8520b1cd2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["가장 높은 점수, 파라미터 : 0.9823910146582906, {'n_neighbors': 3}\n","테스트 데이터 점수 : 0.9532163742690059\n","가장 높은 점수, 파라미터 : 0.9823910146582906, {'n_neighbors': 3}\n","테스트 데이터 점수 : 0.9532163742690059\n","가장 높은 점수, 파라미터 : 0.621494422568473, {'n_neighbors': 35}\n","테스트 데이터 점수 : 0.6280997554371417\n","가장 높은 점수, 파라미터 : 0.6191282216089761, {'n_neighbors': 19}\n","테스트 데이터 점수 : 0.6275082445425657\n"]}]},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 3. Naive Bayes\n","# 회귀문제와 분류문제 둘다에 쓸 수 있다.\n","# 분류는 sklearn.naive_bayes 안의 GaussianNB\n","# 회귀는 sklearn.linear_model 안의 BayesianRidge가 적합하다.\n","\n","# 분류문제\n","data = pd.read_csv(\"breast-cancer-wisconsin.csv\")\n","\n","x = data[data.columns[:10]]\n","y = data[[\"Class\"]]\n","\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42, stratify = y)\n","\n","from sklearn.preprocessing import MinMaxScaler\n","scaler_minmax = MinMaxScaler()\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.naive_bayes import GaussianNB\n","model = GaussianNB()\n","model.fit(x_scaled_train, y_train)\n","pred_train = model.predict(x_scaled_train)\n","print(f\"기본 하이퍼파라미터 테스트 데이터 점수 : {model.score(x_scaled_test, y_test)}\")\n","\n","# 회귀문제\n","data2 = pd.read_csv(\"house_price.csv\")\n","x = data2[data2.columns[:5]]\n","y = data2[[\"house_value\"]]\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42)\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.linear_model import BayesianRidge\n","param_grid = {\"alpha_1\": [1e-07, 1e-06, 1e-05, 1e-04, 1e-03, 1e-02, 1e-01, 1, 2, 3, 4], \"lambda_1\": [1e-07, 1e-06, 1e-05, 1e-04, 1e-03, 1e-02, 1e-01, 1, 2, 3, 4]}\n","grid_search = GridSearchCV(BayesianRidge(), param_grid, cv = 5)\n","grid_search.fit(x_scaled_train, y_train)\n","print(f\"가장 높은 점수, 파라미터 : {grid_search.best_score_}, {grid_search.best_params_}\")\n","print(f\"테스트 데이터 점수 : {grid_search.score(x_scaled_test, y_test)}\")\n","\n","param_distrib = {\"alpha_1\": randint(low = 1e-06, high = 10), \"alpha_1\": randint(low = 1e-06, high = 10)}\n","random_search = RandomizedSearchCV(BayesianRidge(), param_distrib, cv = 5, n_iter = 20)\n","random_search.fit(x_scaled_train, y_train)\n","print(f\"가장 높은 점수, 파라미터 : {random_search.best_score_}, {random_search.best_params_}\")\n","print(f\"테스트 데이터 점수 : {random_search.score(x_scaled_test, y_test)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6DHC3_GoPFnD","executionInfo":{"status":"ok","timestamp":1655804841653,"user_tz":-540,"elapsed":15157,"user":{"displayName":"Jeongeum Lee","userId":"01112082482943907602"}},"outputId":"be4717ad-ec59-4e47-ddc4-a1441d2812fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["기본 하이퍼파라미터 테스트 데이터 점수 : 0.9590643274853801\n","가장 높은 점수, 파라미터 : 0.5702758458286303, {'alpha_1': 4, 'lambda_1': 1e-07}\n","테스트 데이터 점수 : 0.5826111202230753\n","가장 높은 점수, 파라미터 : 0.5702758458751108, {'alpha_1': 9}\n","테스트 데이터 점수 : 0.5826111181974689\n"]}]},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 4. 인공신경망\n","# 회귀문제와 분류문제 둘다에 쓸 수 있다.\n","# sklearn.neural_network 안의 MLPClassifier 와 MLPRegressor 바로 그것이다.\n","\n","# 분류문제\n","data = pd.read_csv(\"breast-cancer-wisconsin.csv\")\n","\n","x = data[data.columns[:10]]\n","y = data[[\"Class\"]]\n","\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42, stratify = y)\n","\n","from sklearn.preprocessing import MinMaxScaler\n","scaler_minmax = MinMaxScaler()\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.neural_network import MLPClassifier\n","model = MLPClassifier()\n","model.fit(x_scaled_train, y_train)\n","pred_train = model.predict(x_scaled_train)\n","print(f\"기본 하이퍼파라미터 테스트 데이터 점수 : {model.score(x_scaled_test, y_test)}\")\n","\n","# from sklearn.model_selection import GridSearchCV\n","# param_grid = {\"hidden_layer_sizes\": [10, 30, 50, 100], \"solver\": [\"sgd\", \"adam\"], \"activation\": [\"tanh\", \"relu\"]}\n","# grid_search = GridSearchCV(MLPClassifier(), param_grid, cv = 5)\n","# grid_search.fit(x_scaled_train, y_train)\n","# print(f\"가장 높은 점수, 파라미터 : {grid_search.best_score_}, {grid_search.best_params_}\")\n","# print(f\"테스트 데이터 점수 : {grid_search.score(x_scaled_test, y_test)}\")\n","\n","# from sklearn.model_selection import RandomizedSearchCV\n","# from scipy.stats import randint\n","# param_distrib = {\"hidden_layer_sizes\": randint(low = 10, high = 100), \"solver\": [\"sgd\", \"adam\"], \"activation\": [\"tanh\", \"relu\"]}\n","# random_search = RandomizedSearchCV(MLPClassifier(), param_distrib, cv = 5, n_iter = 10)\n","# random_search.fit(x_scaled_train, y_train)\n","# print(f\"가장 높은 점수, 파라미터 : {random_search.best_score_}, {random_search.best_params_}\")\n","# print(f\"테스트 데이터 점수 : {random_search.score(x_scaled_test, y_test)}\")\n","\n","\n","# 회귀문제\n","data2 = pd.read_csv(\"house_price.csv\")\n","x = data2[data2.columns[:5]]\n","y = data2[[\"house_value\"]]\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42)\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.neural_network import MLPRegressor\n","model = MLPRegressor(hidden_layer_sizes = (64, 64, 64), activation = \"relu\", max_iter = 2000, random_state = 42)\n","model.fit(x_scaled_train, y_train)\n","pred_train = model.predict(x_scaled_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UlLDmLD7qdH4","executionInfo":{"status":"ok","timestamp":1655812792360,"user_tz":-540,"elapsed":102195,"user":{"displayName":"Jeongeum Lee","userId":"01112082482943907602"}},"outputId":"047eaab7-5e49-4362-e828-5826b1b82e37"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["기본 하이퍼파라미터 테스트 데이터 점수 : 0.9649122807017544\n"]}]},{"cell_type":"markdown","source":["# 2022-06-23"],"metadata":{"id":"T8aeSpIcR-kP"}},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 5. 서포트 벡터머신\n","# 회귀문제와 분류문제 둘다에 쓸 수 있다.\n","# sklearn.svm 안의 SVC 와 SVR 바로 그것이다.\n","\n","# 분류문제\n","\n","import pandas as pd\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","data = pd.read_csv(\"breast-cancer-wisconsin.csv\")\n","# data.head()\n","\n","x = data[data.columns[1:10]]\n","y = data[[\"Class\"]]\n","\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42, stratify = y)\n","\n","from sklearn.preprocessing import MinMaxScaler\n","scaler_minmax = MinMaxScaler()\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.svm import SVC\n","model = SVC()\n","model.fit(x_scaled_train, y_train)\n","pred_train = model.predict(x_scaled_train)\n","pred_test = model.predict(x_scaled_test)\n","print(f\"훈련데이터 점수 : {model.score(x_scaled_train, y_train)}\")\n","print(f\"테스트데이터 점수 : {model.score(x_scaled_test, y_test)}\")\n","\n","from sklearn.metrics import confusion_matrix\n","confusion_test = confusion_matrix(y_test, pred_test)\n","# print(confusion_test)\n","from sklearn.metrics import classification_report\n","report = classification_report(y_test, pred_test)\n","# print(report)\n","\n","from sklearn.model_selection import GridSearchCV\n","param_grid = {\"C\": [0.001, 0.01, 0.1, 1, 10, 100], \"gamma\": [0.001, 0.01, 0.1, 1, 10, 100], \"kernel\": [\"rbf\", \"linear\"]}\n","grid_search = GridSearchCV(SVC(), param_grid, cv = 5)\n","grid_search.fit(x_scaled_train, y_train)\n","print(f\"가장 좋은 파라미터 : {grid_search.best_params_}\")\n","print(f\"가장 좋은 점수 : {grid_search.best_score_}\")\n","\n","from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import randint\n","param_distrib = {\"C\": randint(low = 0.001, high = 100), \"gamma\": randint(low = 0.001, high = 100), \"kernel\": [\"rbf\", \"linear\"]}\n","random_search = RandomizedSearchCV(SVC(), param_distrib, cv = 5, n_iter = 20)\n","random_search.fit(x_scaled_train, y_train)\n","print(f\"가장 좋은 파라미터 : {random_search.best_params_}\")\n","print(f\"가장 좋은 점수 : {random_search.best_score_}\")\n","\n","\n","# 회귀문제\n","data2 = pd.read_csv(\"house_price.csv\")\n","x = data2[data2.columns[:5]]\n","y = data2[[\"house_value\"]]\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42)\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.svm import SVR\n","model = SVR(kernel = \"poly\")\n","model.fit(x_scaled_train, y_train)\n","print(f\"훈련데이터 점수 : {model.score(x_scaled_train, y_train)}\")\n","print(f\"테스트데이터 점수 : {model.score(x_scaled_test, y_test)}\")"],"metadata":{"id":"AEAwWI3Kwgi6","executionInfo":{"status":"ok","timestamp":1655985130167,"user_tz":-540,"elapsed":18244,"user":{"displayName":"Jeongeum Lee","userId":"01112082482943907602"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a1ba7dcc-99f8-4457-e39e-9af73b4a8ca7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련데이터 점수 : 0.984375\n","테스트데이터 점수 : 0.9649122807017544\n","가장 좋은 파라미터 : {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n","가장 좋은 점수 : 0.9745669141442985\n","가장 좋은 파라미터 : {'C': 2, 'gamma': 90, 'kernel': 'linear'}\n","가장 좋은 점수 : 0.9745669141442985\n","훈련데이터 점수 : 0.4411532001585847\n","테스트데이터 점수 : 0.45698485085656304\n"]}]},{"cell_type":"markdown","source":["# 2022-06-24"],"metadata":{"id":"OApQsAwfvvsg"}},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 6. Decision Tree\n","# 회귀문제와 분류문제 둘다에 쓸 수 있다.\n","# sklearn.tree 안의 DecisionTreeClassifier 와 DecisionTreeRegressor 바로 그것이다.\n","\n","# 분류문제\n","\n","import pandas as pd\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","data = pd.read_csv(\"breast-cancer-wisconsin.csv\")\n","# data.head()\n","\n","x = data[data.columns[1:10]]\n","y = data[[\"Class\"]]\n","\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42, stratify = y)\n","\n","from sklearn.preprocessing import MinMaxScaler\n","scaler_minmax = MinMaxScaler()\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.tree import DecisionTreeClassifier\n","model = DecisionTreeClassifier()\n","model.fit(x_scaled_train, y_train)\n","pred_train = model.predict(x_scaled_train)\n","pred_test = model.predict(x_scaled_test)\n","print(f\"훈련데이터 점수 : {model.score(x_scaled_train, y_train)}\")\n","print(f\"테스트데이터 점수 : {model.score(x_scaled_test, y_test)}\")\n","\n","from sklearn.metrics import confusion_matrix\n","confusion_test = confusion_matrix(y_test, pred_test)\n","# print(confusion_test)\n","from sklearn.metrics import classification_report\n","report = classification_report(y_test, pred_test)\n","# print(report)\n","\n","from sklearn.model_selection import GridSearchCV\n","param_grid = {\"min_samples_leaf\": range(2, 20, 2), \"max_depth\": range(1, 50, 2)}\n","grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv = 5)\n","grid_search.fit(x_scaled_train, y_train)\n","print(f\"가장 좋은 파라미터 : {grid_search.best_params_}\")\n","print(f\"가장 좋은 점수 : {grid_search.best_score_}\")\n","\n","from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import randint\n","param_distrib = {\"min_samples_leaf\": randint(low = 1, high = 50), \"max_depth\": randint(low = 1, high = 20)}\n","random_search = RandomizedSearchCV(DecisionTreeClassifier(), param_distrib, cv = 5, n_iter = 20)\n","random_search.fit(x_scaled_train, y_train)\n","print(f\"가장 좋은 파라미터 : {random_search.best_params_}\")\n","print(f\"가장 좋은 점수 : {random_search.best_score_}\")\n","\n","\n","# 회귀문제\n","data2 = pd.read_csv(\"house_price.csv\")\n","x = data2[data2.columns[:5]]\n","y = data2[[\"house_value\"]]\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42)\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.tree import DecisionTreeRegressor\n","model = DecisionTreeRegressor()\n","model.fit(x_scaled_train, y_train)\n","print(f\"훈련데이터 점수 : {model.score(x_scaled_train, y_train)}\")\n","print(f\"테스트데이터 점수 : {model.score(x_scaled_test, y_test)}\")\n","\n","from sklearn.model_selection import GridSearchCV\n","param_grid = {\"min_samples_leaf\": range(2, 20, 2), \"max_depth\": range(1, 50, 2)}\n","grid_search = GridSearchCV(DecisionTreeRegressor(), param_grid, cv = 5)\n","grid_search.fit(x_scaled_train, y_train)\n","print(f\"가장 좋은 파라미터 : {grid_search.best_params_}\")\n","print(f\"가장 좋은 점수 : {grid_search.best_score_}\")\n","\n","from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import randint\n","param_distrib = {\"min_samples_leaf\": randint(low = 1, high = 50), \"max_depth\": randint(low = 1, high = 20)}\n","random_search = RandomizedSearchCV(DecisionTreeRegressor(), param_distrib, cv = 5, n_iter = 20)\n","random_search.fit(x_scaled_train, y_train)\n","print(f\"가장 좋은 파라미터 : {random_search.best_params_}\")\n","print(f\"가장 좋은 점수 : {random_search.best_score_}\")"],"metadata":{"id":"SGaEoQtL7783","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656012604792,"user_tz":-540,"elapsed":79085,"user":{"displayName":"Jeongeum Lee","userId":"01112082482943907602"}},"outputId":"7e0376f0-b0a2-4706-9cac-240235cee638"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련데이터 점수 : 1.0\n","테스트데이터 점수 : 0.9590643274853801\n","가장 좋은 파라미터 : {'max_depth': 17, 'min_samples_leaf': 2}\n","가장 좋은 점수 : 0.9569388920616791\n","가장 좋은 파라미터 : {'max_depth': 8, 'min_samples_leaf': 1}\n","가장 좋은 점수 : 0.9608604606891301\n","훈련데이터 점수 : 1.0\n","테스트데이터 점수 : 0.30850389391214716\n","가장 좋은 파라미터 : {'max_depth': 9, 'min_samples_leaf': 18}\n","가장 좋은 점수 : 0.5792661683673163\n","가장 좋은 파라미터 : {'max_depth': 15, 'min_samples_leaf': 46}\n","가장 좋은 점수 : 0.584687936692273\n"]}]},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 7. Random Forest\n","# 회귀문제와 분류문제 둘다에 쓸 수 있다.\n","# sklearn.ensemble 안의 RandomForestClassifier 와 RandomForestRegressor 바로 그것이다.\n","\n","# 분류문제\n","\n","import pandas as pd\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","data = pd.read_csv(\"breast-cancer-wisconsin.csv\")\n","# data.head()\n","\n","x = data[data.columns[1:10]]\n","y = data[[\"Class\"]]\n","\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42, stratify = y)\n","\n","from sklearn.preprocessing import MinMaxScaler\n","scaler_minmax = MinMaxScaler()\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.ensemble import RandomForestClassifier\n","model = RandomForestClassifier()\n","model.fit(x_scaled_train, y_train)\n","pred_train = model.predict(x_scaled_train)\n","pred_test = model.predict(x_scaled_test)\n","print(f\"훈련데이터 점수 : {model.score(x_scaled_train, y_train)}\")\n","print(f\"테스트데이터 점수 : {model.score(x_scaled_test, y_test)}\")\n","\n","from sklearn.metrics import confusion_matrix\n","confusion_test = confusion_matrix(y_test, pred_test)\n","# print(confusion_test)\n","from sklearn.metrics import classification_report\n","report = classification_report(y_test, pred_test)\n","# print(report)\n","\n","# help(RandomForestClassifier)\n","\n","from sklearn.model_selection import GridSearchCV\n","param_grid = {\"n_estimators\": range(100, 1001, 100), \"max_features\": [\"auto\", \"log2\"]}\n","grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv = 5)\n","grid_search.fit(x_scaled_train, y_train)\n","print(f\"가장 좋은 파라미터 : {grid_search.best_params_}\")\n","print(f\"가장 좋은 점수 : {grid_search.best_score_}\")\n","\n","from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import randint\n","param_distrib = {\"n_estimators\": randint(low = 100, high = 1000), \"max_features\": [\"auto\", \"log2\"]}\n","random_search = RandomizedSearchCV(RandomForestClassifier(), param_distrib, cv = 5, n_iter = 20)\n","random_search.fit(x_scaled_train, y_train)\n","print(f\"가장 좋은 파라미터 : {random_search.best_params_}\")\n","print(f\"가장 좋은 점수 : {random_search.best_score_}\")\n","\n","\n","# 회귀문제\n","data2 = pd.read_csv(\"house_price.csv\")\n","x = data2[data2.columns[:5]]\n","y = data2[[\"house_value\"]]\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42)\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.ensemble import RandomForestRegressor\n","model = RandomForestRegressor()\n","model.fit(x_scaled_train, y_train)\n","print(f\"훈련데이터 점수 : {model.score(x_scaled_train, y_train)}\")\n","print(f\"테스트데이터 점수 : {model.score(x_scaled_test, y_test)}\")\n","\n","# for i in range(100, 500, 100):\n","#     model = RandomForestRegressor(n_estimators = i)\n","#     model.fit(x_scaled_train, y_train)\n","#     print(\"Hey\")\n","#     print(f\"훈련데이터 점수 : {model.score(x_scaled_train, y_train)}\")\n","#     print(f\"테스트데이터 점수 : {model.score(x_scaled_test, y_test)}\")\n","\n","from sklearn.model_selection import GridSearchCV\n","param_grid = {\"n_estimators\": range(100, 500, 100)}\n","grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv = 5)\n","grid_search.fit(x_scaled_train, y_train)\n","print(f\"가장 좋은 파라미터 : {grid_search.best_params_}\")\n","print(f\"가장 좋은 점수 : {grid_search.best_score_}\")\n","\n","from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import randint\n","param_distrib = {\"n_estimators\": randint(low = 100, high = 5500)}\n","random_search = RandomizedSearchCV(RandomForestRegressor(), param_distrib, cv = 5, n_iter = 5)\n","random_search.fit(x_scaled_train, y_train)\n","print(f\"가장 좋은 파라미터 : {random_search.best_params_}\")\n","print(f\"가장 좋은 점수 : {random_search.best_score_}\")"],"metadata":{"id":"7hqeQsYz-GiV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656014144639,"user_tz":-540,"elapsed":76755,"user":{"displayName":"Jeongeum Lee","userId":"01112082482943907602"}},"outputId":"ee2c0d66-f87f-4a57-8c50-154fff6d9829"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련데이터 점수 : 1.0\n","테스트데이터 점수 : 0.9649122807017544\n","훈련데이터 점수 : 0.9458032578290736\n","테스트데이터 점수 : 0.6221515067450613\n","Hey\n","훈련데이터 점수 : 0.9452424753324289\n","테스트데이터 점수 : 0.6251573034882381\n","Hey\n","훈련데이터 점수 : 0.947368268190133\n","테스트데이터 점수 : 0.6235303567620897\n","Hey\n","훈련데이터 점수 : 0.9476565133389108\n","테스트데이터 점수 : 0.6256947644006485\n","Hey\n","훈련데이터 점수 : 0.9477011535374694\n","테스트데이터 점수 : 0.6253613164318899\n"]}]},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 8. 투표기반 앙상블\n","# 회귀문제와 분류문제 둘다에 쓸 수 있다.\n","# sklearn.ensemble 안의 VotingClassifier 와 VotingRegressor 바로 그것이다.\n","\n","# 분류문제\n","\n","import pandas as pd\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","data = pd.read_csv(\"breast-cancer-wisconsin.csv\")\n","# data.head()\n","\n","x = data[data.columns[1:10]]\n","y = data[[\"Class\"]]\n","\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42, stratify = y)\n","\n","from sklearn.preprocessing import MinMaxScaler\n","scaler_minmax = MinMaxScaler()\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","\n","model_svc = SVC(random_state = 42, probability = True)\n","model_logistic = LogisticRegression(random_state = 42)\n","model_rf = RandomForestClassifier(random_state = 42)\n","voting_classifier = VotingClassifier([(\"svc\", model_svc), (\"lg\", model_logistic), (\"rf\", model_rf)], voting = \"soft\")\n","voting_classifier.fit(x_scaled_train, y_train)\n","print(f\"훈련데이터 점수 : {voting_classifier.score(x_scaled_train, y_train)}\")\n","print(f\"테스트데이터 점수 : {voting_classifier.score(x_scaled_test, y_test)}\")\n","\n","# 회귀문제\n","data2 = pd.read_csv(\"house_price.csv\")\n","x = data2[data2.columns[:5]]\n","y = data2[[\"house_value\"]]\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42)\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n","model_linear = LinearRegression()\n","model_rf = RandomForestRegressor(random_state = 42)\n","voting_regressor = VotingRegressor([(\"linear\", model_linear), (\"rf\", model_rf)])\n","voting_regressor.fit(x_scaled_train, y_train)\n","print(f\"훈련데이터 점수 : {voting_regressor.score(x_scaled_train, y_train)}\")\n","print(f\"테스트데이터 점수 : {voting_regressor.score(x_scaled_test, y_test)}\")"],"metadata":{"id":"ecDDd3nj-RZc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656040730614,"user_tz":-540,"elapsed":11334,"user":{"displayName":"Jeongeum Lee","userId":"01112082482943907602"}},"outputId":"e8b73234-7728-462e-95e4-e9c2f7c0adc9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련데이터 점수 : 0.98828125\n","테스트데이터 점수 : 0.9649122807017544\n","훈련데이터 점수 : 0.8128809262725605\n","테스트데이터 점수 : 0.6269061036317223\n"]}]},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 9. 앙상블 배깅\n","# 회귀문제와 분류문제 둘다에 쓸 수 있다.\n","# sklearn.ensemble 안의 BaggingClassifier 와 BaggingRegressor 바로 그것이다.\n","\n","# 분류문제\n","\n","import pandas as pd\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","data = pd.read_csv(\"breast-cancer-wisconsin.csv\")\n","# data.head()\n","\n","x = data[data.columns[1:10]]\n","y = data[[\"Class\"]]\n","\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42, stratify = y)\n","\n","from sklearn.preprocessing import MinMaxScaler\n","scaler_minmax = MinMaxScaler()\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.svm import SVC\n","from sklearn.ensemble import BaggingClassifier\n","model = BaggingClassifier(base_estimator = SVC(), n_estimators = 10, random_state = 42)\n","model.fit(x_scaled_train, y_train)\n","print(f\"훈련데이터 점수 : {model.score(x_scaled_train, y_train)}\")\n","print(f\"테스트데이터 점수 : {model.score(x_scaled_test, y_test)}\")\n","\n","# 회귀문제\n","data2 = pd.read_csv(\"house_price.csv\")\n","x = data2[data2.columns[:5]]\n","y = data2[[\"house_value\"]]\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42)\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.ensemble import BaggingRegressor\n","model = BaggingRegressor(base_estimator = KNeighborsRegressor(), random_state = 42, n_estimators = 10)\n","model.fit(x_scaled_train, y_train)\n","print(f\"훈련데이터 점수 : {model.score(x_scaled_train, y_train)}\")\n","print(f\"테스트데이터 점수 : {model.score(x_scaled_test, y_test)}\")"],"metadata":{"id":"3AWRHwRFETmb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656041048960,"user_tz":-540,"elapsed":3887,"user":{"displayName":"Jeongeum Lee","userId":"01112082482943907602"}},"outputId":"001c90d7-cf2f-4aca-f93c-7b5ab31302cc"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련데이터 점수 : 0.982421875\n","테스트데이터 점수 : 0.9649122807017544\n","훈련데이터 점수 : 0.7305248851529351\n","테스트데이터 점수 : 0.6020446422233702\n"]}]},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 10. 앙상블 부스팅\n","# 회귀문제와 분류문제 둘다에 쓸 수 있다.\n","# sklearn.ensemble 안의 AdaBoostClassifier 와 GradientBoostingClassifier가 분류\n","# AdaBoostRegressor, GradientBoostingRegressor가 회귀\n","\n","# 분류문제\n","\n","import pandas as pd\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","data = pd.read_csv(\"breast-cancer-wisconsin.csv\")\n","# data.head()\n","\n","x = data[data.columns[1:10]]\n","y = data[[\"Class\"]]\n","\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42, stratify = y)\n","\n","from sklearn.preprocessing import MinMaxScaler\n","scaler_minmax = MinMaxScaler()\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n","model_ada = AdaBoostClassifier(n_estimators = 100, random_state = 42)\n","model_grad = GradientBoostingClassifier(random_state = 42)\n","model_ada.fit(x_scaled_train, y_train)\n","model_grad.fit(x_scaled_train, y_train)\n","print(f\"훈련데이터 점수 : {model_ada.score(x_scaled_train, y_train)}\")\n","print(f\"테스트데이터 점수 : {model_ada.score(x_scaled_test, y_test)}\")\n","print(f\"훈련데이터 점수 : {model_grad.score(x_scaled_train, y_train)}\")\n","print(f\"테스트데이터 점수 : {model_grad.score(x_scaled_test, y_test)}\")\n","\n","# 회귀문제\n","data2 = pd.read_csv(\"house_price.csv\")\n","x = data2[data2.columns[:5]]\n","y = data2[[\"house_value\"]]\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42)\n","scaler_minmax.fit(x_train)\n","x_scaled_train = scaler_minmax.transform(x_train)\n","x_scaled_test = scaler_minmax.transform(x_test)\n","\n","from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n","model_ada = AdaBoostRegressor(n_estimators = 100, random_state = 42)\n","model_grad = GradientBoostingRegressor(random_state = 42)\n","model_ada.fit(x_scaled_train, y_train)\n","model_grad.fit(x_scaled_train, y_train)\n","print(f\"훈련데이터 점수 : {model_ada.score(x_scaled_train, y_train)}\")\n","print(f\"테스트데이터 점수 : {model_ada.score(x_scaled_test, y_test)}\")\n","print(f\"훈련데이터 점수 : {model_grad.score(x_scaled_train, y_train)}\")\n","print(f\"테스트데이터 점수 : {model_grad.score(x_scaled_test, y_test)}\")"],"metadata":{"id":"tRuoHbTJF2F6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656041652093,"user_tz":-540,"elapsed":4792,"user":{"displayName":"Jeongeum Lee","userId":"01112082482943907602"}},"outputId":"8dee310c-96a4-4062-c040-ac9dd0199dcf"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["훈련데이터 점수 : 1.0\n","테스트데이터 점수 : 0.9532163742690059\n","훈련데이터 점수 : 1.0\n","테스트데이터 점수 : 0.9649122807017544\n","훈련데이터 점수 : 0.4542136350769076\n","테스트데이터 점수 : 0.4484649534271251\n","훈련데이터 점수 : 0.6528129290117282\n","테스트데이터 점수 : 0.6253634291616165\n"]}]},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 11. 앙상블 스태킹\n","# 회귀문제와 분류문제 둘다에 쓸 수 있다.\n","# sklearn.ensemble 안의 StackingClassifier 와 StackingRegressor 바로 그것이다.\n","\n","# 분류문제\n","\n"],"metadata":{"id":"mJGHvOpjIQjP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 12. 선형회귀모델\n","# Only 회귀문제에만 적용가능.\n","# sklearn.linear_model 안의 LinearRegression 을 사용하면 된다.\n","\n"],"metadata":{"id":"ZM9jRhPlKCSK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 13. 릿지회귀모델\n","# Only 회귀문제에만 적용가능.\n","# sklearn.linear_model 안의 Ridge 를 사용하면 된다.\n","# 하이퍼파라미터 알파가 0이면 LinearRegression과 동일.\n","\n"],"metadata":{"id":"MB1Zb2yK6qGR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 14. 라쏘회귀모델\n","# Only 회귀문제에만 적용가능.\n","# sklearn.linear_model 안의 Lasso 를 사용하면 된다.\n"],"metadata":{"id":"_KDxgQ7x6z5o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 15. 엘라스틱넷\n","# Only 회귀문제에만 적용가능.\n","# sklearn.linear_model 안의 ElasticNet 를 사용하면 된다.\n"],"metadata":{"id":"Gf6dtyKL60Pr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 16. 군집분석\n","# 비지도학습 알고리즘\n","# sklearn.cluster 안의 KMeans 를 보통 많이 사용한다.\n","# 코드는 생략하겠다. 군집분석이 시험에 나오면 포기하자.\n"],"metadata":{"id":"rhGnIJk766Wz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 17. DBSCAN\n","# 비지도학습 알고리즘\n","# sklearn.cluster 안의 DBSCAN 을 사용하면 된다.\n","# 코드는 생략하겠다. DBSCAN이 시험에 나오면 포기하자.\n"],"metadata":{"id":"enRyXxhs66mz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 머신러닝 핵심 알고리즘 - 18. 연관규칙분석\n","# 비지도학습 알고리즘\n","# apyori 안의 apriori 를 사용하면 된다.\n","# 코드는 생략하겠다. 연관규칙분석이 시험에 나오면 포기하자.\n"],"metadata":{"id":"L2F4fft_69AE"},"execution_count":null,"outputs":[]}]}